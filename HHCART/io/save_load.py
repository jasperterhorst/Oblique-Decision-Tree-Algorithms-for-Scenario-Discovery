"""
Model Save/Load Utilities (save_load.py)
----------------------------------------
Save and restore full HHCART-D model instances, including trained trees,
metrics, metadata, and dataset references. Output plots and artefacts
can be saved alongside the model but outside the pickled object.
"""

import os
import json
import pickle
from datetime import datetime
from typing import Optional
from pathlib import Path

import pandas as pd
import numpy as np

from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from HHCART.core import HHCartD


# Root folder where all saved models are stored
DATA_ROOT = os.path.join(os.getcwd(), "data")

# Subfolder inside each model folder containing the model files
MODEL_SUBDIR = "model"


def select_model_folder(model_dirs: list[str]) -> str:
    """
    Prompt the user to select a folder from a list of saved model directories.

    Works reliably in both Jupyter and terminal environments by forcing a flush
    before showing the input prompt.

    Args:
        model_dirs (list[str]): List of available folder names under /data.

    Returns:
        str: Selected model folder name.

    Raises:
        ValueError: If user input is invalid.
    """
    print("\nðŸ“‚ Available saved models:\n")
    for i, name in enumerate(model_dirs):
        print(f"  [{i}] {name}")

    import sys
    import time
    # Flush stdout to ensure all printed text is shown before input prompt appears
    sys.stdout.flush()
    time.sleep(0.1)  # Slight delay helps in Jupyter environments for rendering output

    while True:
        try:
            idx = int(input("\nEnter number to load: ").strip())
            if 0 <= idx < len(model_dirs):
                return model_dirs[idx]
            # Inform user about the valid range if they enter invalid number
            print(f"[âš ] Invalid input. Please enter a valid integer index corresponding to the model folder "
                  f"(between 0 and {len(model_dirs) - 1}).")
            sys.stdout.flush()
        except ValueError:
            # Handle non-integer input with a clear message
            print(f"[âš ] Invalid input. Please enter a valid integer index corresponding to the model folder "
                  f"(between 0 and {len(model_dirs) - 1}).")
            sys.stdout.flush()


def save_full_model(model: "HHCartD", name: Optional[str] = None) -> str:
    """
    Save the full HHCART-D model instance to disk, including trees, metrics,
    metadata, and optionally the training data. Output folder is:
        data/<generated_name>/model/

    Args:
        model (HHCartD): Trained model instance to save.
        name (str, optional): Custom name for the model folder. If None, autogenerated.

    Returns:
        str: Path to the folder containing all saved files (i.e., data/<model_name>/).

    Raises:
        OSError: If folder creation or file writing fails.
    """
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    depth_label = f"depth_{model.max_depth}"
    model_name = name or f"hhcart_d_{depth_label}_{timestamp}"

    # Compose paths for root and model data subfolder
    model_root = os.path.join(DATA_ROOT, model_name)
    model_dir = os.path.join(model_root, MODEL_SUBDIR)

    try:
        # Create directories, if they don't exist
        os.makedirs(model_dir, exist_ok=True)
    except OSError as e:
        raise OSError(f"Failed to create directory {model_dir}: {e}")

    # Save decision trees by depth as a pickle file
    with open(os.path.join(model_dir, "trees.pkl"), "wb") as f:
        pickle.dump(model.trees_by_depth, f)

    # Save metrics dataframe as CSV for easy inspection and analysis
    model.metrics_df.to_csv(os.path.join(model_dir, "metrics.csv"), index=False)

    # Save training features (X) if available and valid
    if hasattr(model, "X") and isinstance(model.X, pd.DataFrame):
        model.X.to_csv(os.path.join(model_dir, "X.csv"), index=False)
    else:
        print("[âš ] Model has no valid 'X' attribute to save.")

    # Save training labels (y) if available
    if hasattr(model, "y"):
        y_path = os.path.join(model_dir, "y.csv")
        if isinstance(model.y, (pd.Series, pd.DataFrame)):
            model.y.to_csv(y_path, index=False)
        elif isinstance(model.y, np.ndarray):
            pd.DataFrame(model.y).to_csv(y_path, index=False, header=False)
        else:
            print("[âš ] Model 'y' attribute is not a known type (pd.Series, pd.DataFrame, np.ndarray). Skipping save.")
    else:
        print("[âš ] Model has no 'y' attribute to save.")

    # Save metadata with relevant parameters and timestamp for reproducibility
    metadata = {
        "max_depth": model.max_depth,
        "min_samples_split": model.min_samples_split,
        "min_purity": model.min_purity,
        "tau": model.tau,
        "random_state": model.random_state,
        "saved_at": timestamp,
    }
    with open(os.path.join(model_dir, "metadata.json"), "w") as f:
        json.dump(metadata, f, indent=4)

    print(f"[ðŸ’¾] HHCART-D model saved to: {model_dir}")
    return model_root


def load_full_model(path: Optional[str] = None) -> "HHCartD":
    """
    Load a previously saved HHCART-D model from disk. Expects the model files to be under:
        data/<model_name>/model/

    Args:
        path (str, optional): Path to specific model folder or folder name under /data.
            If None, user is prompted to select a model folder.

    Returns:
        HHCartD: Fully restored model instance.

    Raises:
        FileNotFoundError: If /data directory, model folder, or required files are missing.
        ValueError: If user input is invalid when prompted.
    """
    if path is None:
        # Check that the /data directory exists
        if not os.path.exists(DATA_ROOT):
            raise FileNotFoundError(
                f"The data directory '{DATA_ROOT}' does not exist. "
                f"Please save a model first before loading."
            )

        # List subdirectories in /data
        model_dirs = sorted([
            d for d in os.listdir(DATA_ROOT)
            if os.path.isdir(os.path.join(DATA_ROOT, d))
        ])
        if not model_dirs:
            raise FileNotFoundError(
                f"No saved model folders found inside '{DATA_ROOT}'. "
                f"Please save a model first before loading."
            )

        # Prompt user to select one folder
        selected = select_model_folder(model_dirs)
        path = os.path.join(DATA_ROOT, selected)

    else:
        # If the given path is relative and does not exist directly,
        # try prefixing it with DATA_ROOT automatically for convenience
        if not os.path.isabs(path) and not os.path.exists(path):
            possible_path = os.path.join(DATA_ROOT, path)
            if os.path.exists(possible_path):
                path = possible_path
            else:
                raise FileNotFoundError(
                    f"Provided path '{path}' does not exist "
                    f"and '{possible_path}' does not exist either."
                )

    model_dir = os.path.join(path, MODEL_SUBDIR)
    if not os.path.exists(model_dir):
        raise FileNotFoundError(
            f"Expected model directory 'model/' not found inside: '{path}'. "
            f"Please check your path and folder structure."
        )

    from HHCART.core import HHCartD

    # Load decision trees
    try:
        with open(os.path.join(model_dir, "trees.pkl"), "rb") as f:
            trees_by_depth = pickle.load(f)
    except Exception as e:
        raise FileNotFoundError(
            f"Could not load trees.pkl from '{model_dir}': {e}"
        )

    # Load metrics dataframe
    try:
        metrics_df = pd.read_csv(os.path.join(model_dir, "metrics.csv"))
        metrics_by_depth = {
            int(row["depth"]): row.to_dict()
            for _, row in metrics_df.iterrows()
        }
    except Exception as e:
        print(f"[âš ] Warning: Failed to load metrics.csv: {e}")
        metrics_df = pd.DataFrame()
        metrics_by_depth = {}

    # Load metadata if exists, else fallback to reasonable defaults
    metadata_path = os.path.join(model_dir, "metadata.json")
    if os.path.exists(metadata_path):
        with open(metadata_path, "r") as f:
            metadata = json.load(f)
    else:
        print(f"[âš ] metadata.json not found in '{model_dir}', using defaults.")
        metadata = {
            "max_depth": max(trees_by_depth.keys()) if trees_by_depth else 6,
            "min_samples_split": 2,
            "min_purity": 1.0,
            "tau": 0.05,
            "random_state": None,
        }

    # Load training data if present, else fallback to empty DataFrames
    try:
        X = pd.read_csv(os.path.join(model_dir, "X.csv"))
    except FileNotFoundError:
        print(f"[âš ] X.csv not found in '{model_dir}', loading empty DataFrame instead.")
        X = pd.DataFrame()

    try:
        y_raw = pd.read_csv(os.path.join(model_dir, "y.csv"), header=None)
        y = y_raw.squeeze()
    except FileNotFoundError:
        print(f"[âš ] y.csv not found in '{model_dir}', loading empty Series instead.")
        y = pd.Series()

    # Instantiate model with loaded data and metadata
    model = HHCartD(
        X=X,
        y=y,
        max_depth=metadata["max_depth"],
        min_samples_split=metadata["min_samples_split"],
        min_purity=metadata["min_purity"],
        tau=metadata["tau"],
        random_state=metadata["random_state"]
    )

    # Attach loaded model internals
    model.trees_by_depth = trees_by_depth
    model.metrics_by_depth = metrics_by_depth
    model.metrics_df = metrics_df

    model.save_dir = Path(path)

    print(f"[âœ…] Model successfully loaded from: {model_dir}")
    return model
